import asyncio
import configparser
import hashlib
import json
import logging
import os
import random
import re
import urllib.parse
from concurrent.futures import ThreadPoolExecutor
from datetime import datetime
from time import sleep
from typing import Any, Dict, List, Optional, Tuple, Union

import pandas as pd
import requests
from bs4 import BeautifulSoup

# Initialize absl logging
try:
    from absl import logging as absl_logging
    absl_logging.use_absl_handler()
    absl_logging.set_verbosity(absl_logging.INFO)
except ImportError:
    pass

# Try importing playwright (optional dependency)
try:
    from playwright.sync_api import TimeoutError, sync_playwright

    PLAYWRIGHT_AVAILABLE = True
except ImportError:
    PLAYWRIGHT_AVAILABLE = False

from utils.caching import FileCache, cache_result

from ..data_models import Product
from . import BaseMultiLayerScraper


class NaverShoppingAPI(BaseMultiLayerScraper):
    """
    ë„¤ì´ë²„ ì‡¼í•‘ API - ê³µì‹ API í™œìš© ì—”ì§„

    íŠ¹ì§•:
    - ë„¤ì´ë²„ ê²€ìƒ‰ API í™œìš©
    - ë¹„ë™ê¸° ì‘ì—… ì²˜ë¦¬
    - ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ë°ì´í„° êµ¬ì¡°
    - ìºì‹± ì§€ì›
    """

    def __init__(
        self,
        client_id: str,
        client_secret: str,
        max_retries: int = 5,
        cache: Optional[FileCache] = None,
        timeout: int = 30,
    ):
        super().__init__(max_retries=max_retries, cache=cache, timeout=timeout)

        # ë„¤ì´ë²„ API ì¸ì¦ ì •ë³´
        self.client_id = client_id
        self.client_secret = client_secret

        # API ê¸°ë³¸ URL ë° ì„¤ì •
        self.api_url = "https://openapi.naver.com/v1/search/shop.json"

        # ê¸°ë³¸ í—¤ë” ì„¤ì •
        self.headers = {
            "X-Naver-Client-Id": self.client_id,
            "X-Naver-Client-Secret": self.client_secret,
            "Accept": "application/json",
        }

        # Define promotional site keywords (ê¸°ì¡´ ì½”ë“œì—ì„œ ìœ ì§€)
        self.promo_keywords = [
            "ì˜¨ì˜¤í”„ë§ˆì¼“",
            "ë‹µë¡€í’ˆ",
            "ê¸°í”„íŠ¸",
            "íŒì´‰",
            "ê¸°ë…í’ˆ",
            "ì¸ì‡„",
            "ê°ì¸",
            "ì œì‘",
            "í™ë³´",
            "ë¯¸ìŠ¤í„°ëª½í‚¤",
            "í˜¸ê°±íƒˆì¶œ",
            "ê³ ë ¤ê¸°í”„íŠ¸",
            "íŒì´‰ë¬¼",
            "ê¸°ì—…ì„ ë¬¼",
            "ë‹¨ì²´ì„ ë¬¼",
            "í–‰ì‚¬ìš©í’ˆ",
            "í™ë³´ë¬¼",
            "ê¸°ì—…í™ë³´",
            "ë¡œê³ ì¸ì‡„",
            "ë¡œê³ ê°ì¸",
            "ë¡œê³ ì œì‘",
            "ê¸°ì—…ë‹µë¡€í’ˆ",
            "í–‰ì‚¬ë‹µë¡€í’ˆ",
            "ê¸°ë…í’ˆì œì‘",
            "ê¸°ì—…ê¸°ë…í’ˆ",
        ]

        # Define promotional product categories (ê¸°ì¡´ ì½”ë“œì—ì„œ ìœ ì§€)
        self.promo_categories = [
            "ê¸°ì—…ì„ ë¬¼",
            "ë‹¨ì²´ì„ ë¬¼",
            "í–‰ì‚¬ìš©í’ˆ",
            "í™ë³´ë¬¼",
            "ê¸°ì—…í™ë³´",
            "ë¡œê³ ì¸ì‡„",
            "ë¡œê³ ê°ì¸",
            "ë¡œê³ ì œì‘",
            "ê¸°ì—…ë‹µë¡€í’ˆ",
            "í–‰ì‚¬ë‹µë¡€í’ˆ",
            "ê¸°ë…í’ˆì œì‘",
            "ê¸°ì—…ê¸°ë…í’ˆ",
            "ê¸°ì—…í™ë³´ë¬¼",
            "ê¸°ì—…í™ë³´ë¬¼ì œì‘",
            "ê¸°ì—…í™ë³´ë¬¼ì¸ì‡„",
            "ê¸°ì—…í™ë³´ë¬¼ê°ì¸",
            "ê¸°ì—…í™ë³´ë¬¼ì œì‘",
        ]

        # Setup logging
        self.logger = logging.getLogger(__name__)

        # Setup image comparison parameters
        self.require_image_match = (
            True  # ë§¤ë‰´ì–¼ ìš”êµ¬ì‚¬í•­: ì´ë¯¸ì§€ì™€ ê·œê²©ì´ ë™ì¼í•œ ê²½ìš°ë§Œ ë™ì¼ìƒí’ˆìœ¼ë¡œ íŒë‹¨
        )

        # Setup price filter
        self.min_price_diff_percent = 10  # ë§¤ë‰´ì–¼ ìš”êµ¬ì‚¬í•­: 10% ì´í•˜ ê°€ê²©ì°¨ì´ ì œí’ˆ ì œì™¸

        self.max_pages = 3  # ë§¤ë‰´ì–¼ ìš”êµ¬ì‚¬í•­: ìµœëŒ€ 3í˜ì´ì§€ê¹Œì§€ë§Œ íƒìƒ‰

        # ê²°ê³¼ ê°œìˆ˜ ì„¤ì • (ìµœëŒ€ 100)
        self.display = 100

        # DNS ìºì‹œ ì„¤ì •
        self.session = requests.Session()
        self.session.verify = False  # SSL ì¸ì¦ì„œ ê²€ì¦ ë¹„í™œì„±í™”
        self.session.mount('http://', requests.adapters.HTTPAdapter(
            max_retries=3,
            pool_connections=100,
            pool_maxsize=100
        ))
        self.session.mount('https://', requests.adapters.HTTPAdapter(
            max_retries=3,
            pool_connections=100,
            pool_maxsize=100
        ))

        # ThreadPoolExecutor ì´ˆê¸°í™”
        self.executor = ThreadPoolExecutor(max_workers=10)  # ì ì ˆí•œ ì›Œì»¤ ìˆ˜ ì„¤ì •

    def search_product(
        self, query: str, max_items: int = 50, reference_price: float = 0
    ) -> List[Product]:
        """
        ë„¤ì´ë²„ ì‡¼í•‘ì—ì„œ ì œí’ˆ ê²€ìƒ‰

        Args:
            query: ê²€ìƒ‰ì–´
            max_items: ìµœëŒ€ ê²€ìƒ‰ ê²°ê³¼ ìˆ˜
            reference_price: ì°¸ì¡° ê°€ê²© (10% ë£° ì ìš©ìš©)

        Returns:
            List[Product]: ê²€ìƒ‰ëœ ì œí’ˆ ëª©ë¡
        """
        if self.cache:

            @cache_result(self.cache, key_prefix="naver_api_search")
            def cached_search(q, m, p):
                return self._search_product_logic(q, m, p)

            return cached_search(query, max_items, reference_price)
        else:
            return self._search_product_logic(query, max_items, reference_price)

    def _search_product_logic(
        self, query: str, max_items: int = 50, reference_price: float = 0
    ) -> List[Product]:
        """ë„¤ì´ë²„ ì‡¼í•‘ API ê²€ìƒ‰ í•µì‹¬ ë¡œì§"""
        # ë¹„ë™ê¸° í•¨ìˆ˜ë¥¼ ë™ê¸°ì ìœ¼ë¡œ ì‹¤í–‰
        return asyncio.run(
            self._search_product_async(query, max_items, reference_price)
        )

    async def _search_product_async(
        self, query: str, max_items: int = 50, reference_price: float = 0
    ) -> List[Product]:
        """ë¹„ë™ê¸° ë°©ì‹ìœ¼ë¡œ ì œí’ˆ ê²€ìƒ‰ (ë³‘ë ¬ ì²˜ë¦¬)"""
        products = []

        try:
            self.logger.info(f"Searching Naver Shopping API for '{query}'")

            # ë‚®ì€ ê°€ê²©ìˆœ ì •ë ¬ ì ìš© (ë§¤ë‰´ì–¼ ìš”êµ¬ì‚¬í•­)
            sort = "asc"  # ê°€ê²© ì˜¤ë¦„ì°¨ìˆœ

            # ìµœëŒ€ 3í˜ì´ì§€ê¹Œì§€ ê²€ìƒ‰ (ë§¤ë‰´ì–¼ ìš”êµ¬ì‚¬í•­)
            for page in range(1, self.max_pages + 1):
                page_products = await self._fetch_api_results(query, page, sort)

                if not page_products:
                    break

                # Apply 10% rule if reference price is provided
                if reference_price > 0:
                    filtered_products = []
                    for product in page_products:
                        # Skip products with no price
                        if not product.price:
                            continue

                        # Calculate price difference percentage
                        price_diff_percent = (
                            (product.price - reference_price) / reference_price
                        ) * 100

                        # Include product if price difference is significant enough
                        # (either lower price or at least min_price_diff_percent higher)
                        if (
                            price_diff_percent < 0
                            or price_diff_percent >= self.min_price_diff_percent
                        ):
                            filtered_products.append(product)

                    page_products = filtered_products

                products.extend(page_products)

                # Stop if we have enough products or no more pages
                if len(products) >= max_items:
                    products = products[:max_items]
                    break

                # í˜ì´ì§€ ê°„ ì§€ì—° ì‹œê°„ (API í˜¸ì¶œ ì œí•œ ê³ ë ¤)
                wait_time = 0.5 + random.uniform(0.2, 0.5)
                self.logger.debug(
                    f"Waiting {wait_time:.2f} seconds before fetching next page"
                )
                await asyncio.sleep(wait_time)

            if not products:
                self.logger.info(
                    f"No products found for '{query}' on Naver Shopping API"
                )
                # ë§¤ë‰´ì–¼ ìš”êµ¬ì‚¬í•­: ì°¾ì§€ ëª»í•˜ë©´ "ë™ì¼ìƒí’ˆ ì—†ìŒ"ìœ¼ë¡œ ì²˜ë¦¬
                no_match_product = Product(
                    id="no_match",
                    name=f"ë™ì¼ìƒí’ˆ ì—†ìŒ - {query}",
                    source="naver_shopping",
                    price=0,
                    url="",
                    image_url="",
                )
                products.append(no_match_product)
            else:
                self.logger.info(
                    f"Found {len(products)} products for '{query}' on Naver Shopping API"
                )
                # ì—¬ê¸°ì„œ no_match ì œí’ˆì„ ì¶”ê°€í•˜ì§€ ì•ŠìŒ

            return products

        except Exception as e:
            self.logger.error(
                f"Error searching Naver Shopping API for '{query}': {str(e)}",
                exc_info=True,
            )
            return []

    async def _fetch_api_results(
        self, query: str, page: int, sort: str = "asc"
    ) -> List[Product]:
        """ë„¤ì´ë²„ ì‡¼í•‘ API í˜¸ì¶œí•˜ì—¬ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°"""
        # Create cache key for this query and page
        cache_key = f"naver_api|{query}|{page}|{sort}"
        cached_result = self.get_sparse_data(cache_key)
        if cached_result:
            return cached_result

        # API ìš”ì²­ íŒŒë¼ë¯¸í„° ì„¤ì •
        params = {
            "query": query,
            "display": self.display,  # í•œ í˜ì´ì§€ë‹¹ ê²°ê³¼ ìˆ˜ (ìµœëŒ€ 100)
            "start": (page - 1) * self.display + 1,  # í˜ì´ì§€ ì‹œì‘ì 
            "sort": sort,  # ì •ë ¬ (asc: ê°€ê²© ì˜¤ë¦„ì°¨ìˆœ)
            "filter": "naverpay",  # ë„¤ì´ë²„í˜ì´ ì—°ë™ ìƒí’ˆë§Œ (ì„ íƒì )
            "exclude": "used:rental",  # ì¤‘ê³ , ë Œíƒˆ ì œì™¸
        }

        loop = asyncio.get_running_loop()
        retry_count = 0
        max_retries = self.max_retries
        retry_delay = 1.0

        while retry_count <= max_retries:
            try:
                # API ìš”ì²­ ì‹¤í–‰
                response = await loop.run_in_executor(
                    self.executor,
                    lambda: requests.get(
                        self.api_url,
                        headers=self.headers,
                        params=params,
                        timeout=self.timeout,
                    ),
                )

                # ë” ìì„¸í•œ ì‘ë‹µ ë¡œê¹… ì¶”ê°€
                self.logger.debug(f"API ìš”ì²­: {self.api_url}")
                self.logger.debug(f"í—¤ë”: {self.headers}")
                self.logger.debug(f"íŒŒë¼ë¯¸í„°: {params}")
                self.logger.info(f"ì‘ë‹µ ìƒíƒœ ì½”ë“œ: {response.status_code}")

                # ì‘ë‹µ ë‚´ìš© ì „ì²´ ë¡œê¹… (ë””ë²„ê¹…ìš©)
                response_text = response.text
                self.logger.info(
                    f"ì‘ë‹µ ë‚´ìš©: {response_text[:200]}..."
                )  # ì‘ë‹µì˜ ì²˜ìŒ 200ìë§Œ ë¡œê·¸ì— ì¶œë ¥

                # ì‘ë‹µ ìƒíƒœ ì½”ë“œ í™•ì¸
                if response.status_code == 429:  # Too Many Requests
                    retry_count += 1
                    wait_time = retry_delay * (2 ** (retry_count - 1))
                    self.logger.warning(
                        f"Rate limit exceeded. Retrying in {wait_time} seconds (attempt {retry_count}/{max_retries})"
                    )
                    await asyncio.sleep(wait_time)
                    continue

                elif response.status_code != 200:
                    self.logger.error(
                        f"API request failed with status code {response.status_code}: {response.text}"
                    )
                    return []

                # JSON ì‘ë‹µ íŒŒì‹±
                data = response.json()

                # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš°
                if data.get("total", 0) == 0 or not data.get("items"):
                    self.logger.info(f"No results found for '{query}' on page {page}")
                    return []

                # ê²°ê³¼ ìš”ì•½ ë¡œê¹…
                self.logger.info(
                    f"ì´ ê²€ìƒ‰ ê²°ê³¼: {data.get('total', 0)}ê°œ, í˜„ì¬ í˜ì´ì§€ ì•„ì´í…œ: {len(data.get('items', []))}ê°œ"
                )

                # ì œí’ˆ ë°ì´í„° ë³€í™˜
                products = []
                for item in data.get("items", []):
                    product = await self._convert_api_item_to_product(item)
                    if product:
                        products.append(product)

                # ìºì‹œì— ì €ì¥
                if products:
                    if self.cache:
                        self.cache_sparse_data(f"naver_api_{query}_{page}", products)

                return products

            except Exception as e:
                retry_count += 1
                if retry_count <= max_retries:
                    wait_time = retry_delay * (2 ** (retry_count - 1))
                    self.logger.warning(
                        f"Error during API request: {str(e)}. Retrying in {wait_time} seconds (attempt {retry_count}/{max_retries})"
                    )
                    await asyncio.sleep(wait_time)
                else:
                    self.logger.error(
                        f"Failed to fetch API results after {max_retries} retries: {str(e)}"
                    )
                    return []

        return []

    async def _convert_api_item_to_product(
        self, item: Dict
    ) -> Optional[Product]:
        """API ì‘ë‹µ ì•„ì´í…œì„ Product ê°ì²´ë¡œ ë³€í™˜"""
        try:
            # HTML íƒœê·¸ ì œê±°
            title = re.sub(r"<[^>]+>", "", item.get("title", ""))

            # ê°€ê²© ì¶”ì¶œ
            price = int(item.get("lprice", 0))

            # ì œí’ˆ ID ìƒì„±
            product_id = (
                item.get("productId", "")
                or hashlib.md5(item.get("link", "").encode()).hexdigest()
            )

            # ì¹´í…Œê³ ë¦¬ ì •ë³´
            category = item.get("category1", "")
            if item.get("category2"):
                category += f" > {item.get('category2')}"
            if item.get("category3"):
                category += f" > {item.get('category3')}"
            if item.get("category4"):
                category += f" > {item.get('category4')}"

            # íŒë§¤ì²˜ ì •ë³´
            mall_name = item.get("mallName", "")

            # ì´ë¯¸ì§€ URL - ë„¤ì´ë²„ API ì‘ë‹µì—ì„œ image í•„ë“œëŠ” í•­ìƒ ìˆì–´ì•¼ í•¨
            # ì°¸ê³ : ë„¤ì´ë²„ ê²€ìƒ‰ API ë¬¸ì„œì— ë”°ë¥´ë©´ ëª¨ë“  ìƒí’ˆì—ëŠ” ì´ë¯¸ì§€ URLì´ í¬í•¨ë¨
            image_url = item.get("image", "")

            # ì´ë¯¸ì§€ê°€ ì—†ëŠ” ê²½ìš° ë¡œê¹… (ë””ë²„ê¹… ëª©ì )
            if not image_url:
                self.logger.warning(
                    f"ğŸ–¼ï¸ ë„¤ì´ë²„ APIì—ì„œ ë°˜í™˜ëœ ìƒí’ˆ '{title}'ì˜ ì´ë¯¸ì§€ URLì´ ì—†ìŠµë‹ˆë‹¤"
                )
                self.logger.debug(
                    f"ë„¤ì´ë²„ API ì‘ë‹µ ì•„ì´í…œ êµ¬ì¡°: {json.dumps(item, indent=2, ensure_ascii=False)}"
                )

            # í™ë³´ì„± ì œí’ˆ ì—¬ë¶€ í™•ì¸
            is_promotional = self._is_promotional_product(title, mall_name, category)

            # Product ê°ì²´ ìƒì„±
            product = Product(
                id=product_id,
                name=title,
                price=price,
                source="naver_api",
                url=item.get("link", ""),
                image_url=image_url,
                brand=mall_name,
                category=category,
                is_promotional_site=is_promotional,
                original_input_data=item,
            )

            return product
        except Exception as e:
            self.logger.error(
                f"Error converting API item to Product: {str(e)}", exc_info=True
            )
            return None

    def _is_promotional_product(
        self, title: str, mall_name: str, category: str
    ) -> bool:
        """í™ë³´ì„± ì œí’ˆ ì—¬ë¶€ í™•ì¸ (ê¸°ì¡´ ì½”ë“œì—ì„œ ìœ ì§€)"""
        if not title:
            return False

        title_lower = title.lower()
        mall_name_lower = mall_name.lower() if mall_name else ""
        category_lower = category.lower() if category else ""

        # Check title against promotional keywords
        for keyword in self.promo_keywords:
            if keyword in title_lower or keyword in mall_name_lower:
                return True

        # Check category against promotional categories
        for cat in self.promo_categories:
            if cat in category_lower:
                return True

        return False

    def process_file(self, input_file: str) -> Tuple[Optional[str], Optional[str]]:
        """Process input Excel file and generate reports."""
        self.logger.error("This method is not fully implemented")
        return None, None


class NaverPriceTableCrawler:
    """
    ë„¤ì´ë²„ ì‡¼í•‘ ë° ì—°ê²°ëœ ì‡¼í•‘ëª°ì—ì„œ ê°€ê²©í‘œ ì¶”ì¶œ

    íŠ¹ì§•:
    - Playwright ì‚¬ìš©
    - ë‹¤ì–‘í•œ ì‚¬ì´íŠ¸ì˜ ê°€ê²©í‘œ ì¶”ì¶œ ì§€ì›
    - ë¶€ê°€ì„¸ ìë™ ê³„ì‚°
    - ìˆ˜ëŸ‰ë³„ ê°€ê²© ì¶”ì¶œ
    - í’ˆì ˆ ì—¬ë¶€ ê°ì§€
    """

    def __init__(self, output_dir: str = "output", headless: bool = True):
        """
        ê°€ê²©í‘œ í¬ë¡¤ëŸ¬ ì´ˆê¸°í™”

        Args:
            output_dir: ì¶”ì¶œí•œ ê°€ê²©í‘œë¥¼ ì €ì¥í•  ë””ë ‰í† ë¦¬
            headless: í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œ ì—¬ë¶€ (ë¸Œë¼ìš°ì € í‘œì‹œí•˜ì§€ ì•ŠìŒ)
        """
        self.output_dir = output_dir
        self.headless = headless
        self.logger = logging.getLogger(__name__)
        self.dialog_message = ""  # ëŒ€í™” ìƒì ë©”ì‹œì§€ ì €ì¥

        # ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ë°˜í™˜ê°’
        self.default_result = None, False, "Not available"

        if not PLAYWRIGHT_AVAILABLE:
            self.logger.warning(
                "Playwright is not installed. Price table extraction will not work."
            )

        # ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(output_dir, exist_ok=True)

    def _handle_dialog(self, dialog):
        """ëŒ€í™” ìƒì ì²˜ë¦¬ (í’ˆì ˆ ë“± ìƒíƒœ ë©”ì‹œì§€ í™•ì¸ìš©)"""
        self.dialog_message = dialog.message
        self.logger.debug(f"Dialog message: {dialog.message}")
        dialog.accept()

    def _remove_special_chars(self, value):
        """ë¬¸ìì™€ íŠ¹ìˆ˜ ë¬¸ìë¥¼ ì œê±° (ìˆ«ìë§Œ ì¶”ì¶œ)"""
        try:
            return "".join(filter(str.isdigit, str(value)))
        except (TypeError, ValueError):
            return value

    def _clean_quantity(self, qty):
        """ìˆ˜ëŸ‰ ë¯¸ë§Œ ì²˜ë¦¬ í•¨ìˆ˜"""
        if isinstance(qty, str) and "ë¯¸ë§Œ" in qty:
            return "0"
        else:
            try:
                return "".join(filter(str.isdigit, str(qty)))
            except (TypeError, ValueError):
                return qty

    def get_price_table(self, url: str) -> Tuple[Optional[pd.DataFrame], bool, str]:
        """URLì—ì„œ ê°€ê²©í‘œ ê°€ì ¸ì˜¤ê¸°"""
        if not PLAYWRIGHT_AVAILABLE:
            self.logger.error("Playwright is not installed. Cannot crawl price table.")
            return None, False, "Playwright ì„¤ì¹˜ í•„ìš”"

        self.dialog_message = ""  # ëŒ€í™” ìƒì ë©”ì‹œì§€ ì´ˆê¸°í™”

        try:
            with sync_playwright() as p:
                browser = p.chromium.launch(headless=self.headless)
                context = browser.new_context()
                page = context.new_page()
                page.on("dialog", self._handle_dialog)

                # í˜ì´ì§€ ë¡œë“œ
                page.goto(url, wait_until="networkidle")

                # ë„¤ì´ë²„ ì‡¼í•‘ ë§í¬ì¸ ê²½ìš°, ìµœì €ê°€ ì‚¬ëŸ¬ê°€ê¸° ë§í¬ ì¶”ì¶œ
                if "naver.com" in url and "shopping" in url:
                    try:
                        lowest_price_link = page.locator(
                            '//div[contains(@class, "lowestPrice_btn_box")]/div[contains(@class, "buyButton_compare_wrap")]/a[text()="ìµœì €ê°€ ì‚¬ëŸ¬ê°€ê¸°"]'
                        ).get_attribute("href")
                        if lowest_price_link:
                            self.logger.info(
                                "ìµœì €ê°€ ì‚¬ëŸ¬ê°€ê¸° ë§í¬ ë°œê²¬. í•´ë‹¹ í˜ì´ì§€ë¡œ ì´ë™í•©ë‹ˆë‹¤."
                            )
                            page.goto(lowest_price_link, wait_until="networkidle")
                    except Exception as e:
                        self.logger.warning(
                            f"Failed to find or navigate to lowest price link: {e}"
                        )

                # í’ˆì ˆ í™•ì¸
                is_sold_out = False
                if self.dialog_message and (
                    "ìƒí’ˆ" in self.dialog_message
                    or "ì¬ê³ " in self.dialog_message
                    or "í’ˆì ˆ" in self.dialog_message
                ):
                    is_sold_out = True
                    self.logger.info(f"ìƒí’ˆ í’ˆì ˆ í™•ì¸: {self.dialog_message}")
                    browser.close()
                    return None, is_sold_out, self.dialog_message

                # ê° XPathì™€ ì—°ê²°ëœ í•¨ìˆ˜ ì‹¤í–‰
                xpath_to_function = {
                    '//div[@class = "price-box"]': self._handle_login_one,  # ë¶€ê°€ì„¸ ë³„ë„
                    '//div[@class = "tbl02"]': self._handle_login_one,  # ë¶€ê°€ì„¸ ë³„ë„
                    '//table[@class = "hompy1004_table_class hompy1004_table_list"]/ancestor::td[1]': self._handle_login_two,  # ë¶€ê°€ì„¸ ë³„ë„
                    '//table[@class = "goods_option"]//td[@colspan = "4"]': self._handle_login_three,  # ë¶€ê°€ì„¸ ë³„ë„
                    '//div[@class = "vi_info"]//div[@class = "tbl_frm01"]': self._handle_login_one,  # ë¶€ê°€ì„¸ ë³„ë„
                    '//div[@class = "specArea"]//div[@class = "w100"]': self._handle_login_one,
                }

                result_df = None

                # ê° XPathì™€ ì—°ê²°ëœ í•¨ìˆ˜ ì‹¤í–‰
                for xpath, function in xpath_to_function.items():
                    element = page.query_selector(xpath)
                    if element:
                        html_content = element.inner_html()
                        soup = BeautifulSoup(html_content, "html.parser")
                        result_df = function(soup)  # soupì„ í•¨ìˆ˜ë¡œ ì „ë‹¬

                        if result_df is not None:
                            self.logger.info(f"ê°€ê²©í‘œ ì¶”ì¶œ ì„±ê³µ: {len(result_df)} í–‰")
                            # CSV íŒŒì¼ë¡œ ì €ì¥
                            output_file = f"{self.output_dir}/unit_price_list.csv"
                            result_df.to_csv(output_file, index=False)
                            self.logger.info(f"ê°€ê²©í‘œ ì €ì¥ ì™„ë£Œ: {output_file}")
                            break

                browser.close()

                return result_df, is_sold_out, self.dialog_message

        except Exception as e:
            self.logger.error(f"Error in price table crawling: {e}", exc_info=True)
            return None, False, str(e)

    def _handle_login_one(self, soup):
        """ì²« ë²ˆì§¸ ìœ í˜•ì˜ ê°€ê²©í‘œ ì²˜ë¦¬"""
        try:
            # í…Œì´ë¸” ì°¾ê¸° ì‹œë„
            tables = soup.find_all("table")
            if tables:
                df = pd.read_html(str(tables[0]))[
                    0
                ]  # ì²« ë²ˆì§¸ í…Œì´ë¸”ì„ DataFrameìœ¼ë¡œ ë³€í™˜
                df = df.T
                df.reset_index(drop=False, inplace=True)
                df.columns = df.iloc[0]
                df.drop(index=0, inplace=True)
                df.columns = ["ìˆ˜ëŸ‰", "ì¼ë°˜"]
                df = df.map(self._remove_special_chars)
                df["ì¼ë°˜"] = df["ì¼ë°˜"].apply(lambda x: float(x) * 1.1)  # ë¶€ê°€ì„¸ ì¶”ê°€
                df["ìˆ˜ëŸ‰"] = df["ìˆ˜ëŸ‰"].astype("int64")
                df.sort_values(by="ìˆ˜ëŸ‰", inplace=True, ignore_index=True)
                return df
            else:
                return None
        except Exception as e:
            self.logger.error(f"Error in _handle_login_one: {e}")
            return None

    def _handle_login_two(self, soup):
        """ë‘ ë²ˆì§¸ ìœ í˜•ì˜ ê°€ê²©í‘œ ì²˜ë¦¬"""
        try:
            tables = soup.find_all("table")
            if tables:
                df = pd.read_html(str(tables[0]))[
                    0
                ]  # ì²« ë²ˆì§¸ í…Œì´ë¸”ì„ DataFrameìœ¼ë¡œ ë³€í™˜
                df = df.T
                df.reset_index(drop=False, inplace=True)
                df.columns = df.iloc[0]
                df.drop(index=0, inplace=True)
                df["ìˆ˜ëŸ‰"] = df["ìˆ˜ëŸ‰"].apply(self._clean_quantity)
                df = df.map(self._remove_special_chars)
                try:
                    df.drop("íšŒì›", axis=1, inplace=True)
                except Exception:
                    pass
                df.sort_values(by="ìˆ˜ëŸ‰", inplace=True, ignore_index=True)
                return df
            else:
                return None
        except Exception as e:
            self.logger.error(f"Error in _handle_login_two: {e}")
            return None

    def _handle_login_three(self, soup):
        """ì„¸ ë²ˆì§¸ ìœ í˜•ì˜ ê°€ê²©í‘œ ì²˜ë¦¬"""
        try:
            tables = soup.find_all("table")
            if tables:
                # ì…ë ¥ íƒœê·¸ì—ì„œ ìˆ˜ëŸ‰ê³¼ ê°€ê²© ì¶”ì¶œ
                quantities = []
                prices = []

                for input_tag in soup.find_all("input", class_="qu"):
                    try:
                        quantities.append(int(input_tag["value"]))
                    except (ValueError, KeyError):
                        pass

                for input_tag in soup.find_all("input", class_="pr"):
                    try:
                        prices.append(int(input_tag["value"].replace(",", "")))
                    except (ValueError, KeyError):
                        pass

                if quantities and prices and len(quantities) == len(prices):
                    # ë°ì´í„°í”„ë ˆì„ ìƒì„±
                    df = pd.DataFrame({"ìˆ˜ëŸ‰": quantities, "ì¼ë°˜": prices})
                    df["ì¼ë°˜"] = df["ì¼ë°˜"].apply(
                        lambda x: float(x) * 1.1
                    )  # ë¶€ê°€ì„¸ ì¶”ê°€
                    df.sort_values(by="ìˆ˜ëŸ‰", inplace=True, ignore_index=True)
                    return df
            return None
        except Exception as e:
            self.logger.error(f"Error in _handle_login_three: {e}")
            return None

    def check_stock_status(self, url: str) -> Tuple[bool, str]:
        """ìƒí’ˆ URLì—ì„œ ì¬ê³  ìƒíƒœ í™•ì¸"""
        _, is_sold_out, message = self.get_price_table(url)
        return not is_sold_out, message


class NaverShoppingCrawler(BaseMultiLayerScraper):
    """
    ë„¤ì´ë²„ ì‡¼í•‘ í¬ë¡¤ëŸ¬ - ê³µì‹ APIì™€ ì—°ê²°í•˜ëŠ” ë¸Œë¦¿ì§€ í´ë˜ìŠ¤

    íŠ¹ì§•:
    - .env íŒŒì¼ ë˜ëŠ” ì„¤ì •ì—ì„œ API í‚¤ ë¡œë“œ
    - NaverShoppingAPI í´ë˜ìŠ¤ì˜ ë˜í¼
    - ì¬ì‹œë„ ë° ì˜ˆì™¸ ì²˜ë¦¬
    """

    def __init__(
        self,
        max_retries: int = 5,
        timeout: int = 30,
        cache: Optional[FileCache] = None,
    ):
        super().__init__(max_retries, timeout, cache)
        self.logger = logging.getLogger(__name__)
        self.max_retries = max_retries
        self.timeout = timeout

        # API í‚¤ ë¡œë“œ
        self.api_keys = self._load_api_keys()

        # Naver Shopping API ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        self.api = NaverShoppingAPI(
            client_id=self.api_keys["client_id"],
            client_secret=self.api_keys["client_secret"],
            max_retries=max_retries,
            cache=cache,
            timeout=timeout,
        )

        # ë‹¨ê°€í‘œ í¬ë¡¤ëŸ¬ ìƒì„±
        self.price_table_crawler = NaverPriceTableCrawler(
            output_dir="output",
            headless=False,  # ê°œë°œ/ë””ë²„ê¹… ì‹œ False, ë°°í¬ ì‹œ Trueë¡œ ë³€ê²½
        )

    def _load_api_keys(self) -> Dict[str, str]:
        """
        config.ini íŒŒì¼ì—ì„œ ë„¤ì´ë²„ API í‚¤ ë¡œë“œ
        config.iniì— ì—†ìœ¼ë©´ .env íŒŒì¼ì—ì„œ ì°¾ìŒ
        """
        import os
        from dotenv import load_dotenv

        # config.ini íŒŒì¼ì—ì„œ ë¨¼ì € ì°¾ê¸°
        try:
            config = configparser.ConfigParser()
            config_path = os.path.join(
                os.path.dirname(os.path.dirname(os.path.dirname(__file__))),
                "config.ini",
            )

            if os.path.exists(config_path):
                config.read(config_path, encoding="utf-8")

                if (
                    "API" in config
                    and "NAVER_CLIENT_ID" in config["API"]
                    and "NAVER_CLIENT_SECRET" in config["API"]
                ):
                    client_id = config["API"]["NAVER_CLIENT_ID"]
                    client_secret = config["API"]["NAVER_CLIENT_SECRET"]
                    self.logger.info("API í‚¤ë¥¼ config.ini íŒŒì¼ì—ì„œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
                    return {"client_id": client_id, "client_secret": client_secret}
        except Exception as e:
            self.logger.warning(
                f"config.ini íŒŒì¼ì—ì„œ API í‚¤ë¥¼ ë¡œë“œí•˜ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"
            )

        # config.iniì—ì„œ ì°¾ì§€ ëª»í•˜ë©´ .env íŒŒì¼ì—ì„œ ì°¾ê¸°
        load_dotenv()
        client_id = os.getenv("NAVER_CLIENT_ID")
        client_secret = os.getenv("NAVER_CLIENT_SECRET")

        if not client_id or not client_secret:
            self.logger.error(
                "ë„¤ì´ë²„ API í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. config.inië‚˜ .env íŒŒì¼ì— NAVER_CLIENT_IDì™€ NAVER_CLIENT_SECRETì´ ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”."
            )
            raise ValueError("ë„¤ì´ë²„ API í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        self.logger.info(f"API í‚¤ë¥¼ .env íŒŒì¼ì—ì„œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤. (client_id: {client_id[:4]}...)")
        return {"client_id": client_id, "client_secret": client_secret}

    def search_product(
        self, query: str, max_items: int = 50, reference_price: float = 0
    ) -> List[Product]:
        """
        ë„¤ì´ë²„ ì‡¼í•‘ì—ì„œ ì œí’ˆ ê²€ìƒ‰ - APIë¥¼ í†µí•´ ê²€ìƒ‰ ìˆ˜í–‰

        Args:
            query: ê²€ìƒ‰ì–´
            max_items: ìµœëŒ€ ê²€ìƒ‰ ê²°ê³¼ ìˆ˜
            reference_price: ì°¸ì¡° ê°€ê²© (10% ë£° ì ìš©ìš©)

        Returns:
            List[Product]: ê²€ìƒ‰ëœ ì œí’ˆ ëª©ë¡
        """
        try:
            self.logger.info(f"ë„¤ì´ë²„ ì‡¼í•‘ ê²€ìƒ‰ ì‹œì‘: '{query}'")

            # ê°€ì´ë“œë¼ì¸ ë°˜ì˜: ìƒí’ˆëª…ì—ì„œ '_'ë¥¼ ê³µë°±ìœ¼ë¡œ ì¹˜í™˜
            processed_query = query.replace("_", " ")
            if processed_query != query:
                self.logger.info(f"ê²€ìƒ‰ì–´ ì „ì²˜ë¦¬: '{query}' -> '{processed_query}'")

            # NaverShoppingAPIì˜ search_product ë©”ì„œë“œ í˜¸ì¶œ (ì²˜ë¦¬ëœ ê²€ìƒ‰ì–´ ì‚¬ìš©)
            products = self.api.search_product(
                query=processed_query,
                max_items=max_items,
                reference_price=reference_price,
            )

            if not products:
                self.logger.warning(f"'{processed_query}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                # ê²°ê³¼ê°€ ì—†ì„ ë•Œ no_match ì œí’ˆ ìƒì„±
                no_match_product = Product(
                    id="no_match",
                    name=f"ë™ì¼ìƒí’ˆ ì—†ìŒ - {processed_query}",
                    source="naver_shopping",
                    price=0,
                    url="",
                    image_url="",
                )
                return [no_match_product]
            else:
                self.logger.info(
                    f"'{processed_query}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ {len(products)}ê°œ ë°œê²¬"
                )
                return products

        except Exception as e:
            self.logger.error(f"ë„¤ì´ë²„ ì‡¼í•‘ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True)
            # ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë„ no_match ì œí’ˆ ë°˜í™˜
            no_match_product = Product(
                id="no_match",
                name=f"ê²€ìƒ‰ ì˜¤ë¥˜ - {query}",
                source="naver_shopping",
                price=0,
                url="",
                image_url="",
            )
            return [no_match_product]

    def process_file(self, input_file: str) -> Tuple[Optional[str], Optional[str]]:
        """
        Excel íŒŒì¼ ì²˜ë¦¬í•˜ê³  ë³´ê³ ì„œ ìƒì„±

        Args:
            input_file: ì²˜ë¦¬í•  ì…ë ¥ íŒŒì¼ ê²½ë¡œ

        Returns:
            Tuple[Optional[str], Optional[str]]: ìƒì„±ëœ ë³´ê³ ì„œ íŒŒì¼ ê²½ë¡œ ë° ë¡œê·¸ íŒŒì¼ ê²½ë¡œ
        """
        # ì´ í•¨ìˆ˜ëŠ” ì¶”í›„ êµ¬í˜„ì´ í•„ìš”í•¨
        self.logger.error("process_file ë©”ì„œë“œëŠ” ì•„ì§ êµ¬í˜„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return None, None

    def get_price_table(self, url: str) -> Tuple[Optional[pd.DataFrame], bool, str]:
        """ìƒí’ˆ URLì—ì„œ ë‹¨ê°€í‘œ ê°€ì ¸ì˜¤ê¸°"""
        return self.price_table_crawler.get_price_table(url)

    def check_stock_status(self, url: str) -> Tuple[bool, str]:
        """ìƒí’ˆ URLì—ì„œ ì¬ê³  ìƒíƒœ í™•ì¸"""
        return self.price_table_crawler.check_stock_status(url)
